{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified from: wikipedia_topic_modeling notebook\n",
    "\n",
    "For each model, create a database with columns: (1) article title, (2) url, (3) list of similar articles, (4) list of urls for similar articles, (5) list of similarity scores\n",
    "\n",
    "These databases will be queried in the web application\n",
    "\n",
    "Use default num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melanie\\Anaconda3\\envs\\cdips2017\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from xml.dom import minidom\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('..\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page_type(title):\n",
    "    \"\"\"\n",
    "    from WikiPage.py: extract page type from article title\n",
    "    \"\"\"\n",
    "    if 'Category:' in title:\n",
    "        return 'category'\n",
    "    elif 'Portal:' in title:\n",
    "        return 'portal'\n",
    "    elif 'List of' in title:\n",
    "        return 'list'\n",
    "    elif 'File:' in title:\n",
    "        return 'file'\n",
    "    else:\n",
    "        return 'article'\n",
    "\n",
    "def xml_to_df(xmlfile):\n",
    "    \"\"\"\n",
    "    input: xml filename\n",
    "    output: data frame with columns: article id, title, url, page_type, tokenized text\n",
    "    \n",
    "    filter out pages that are not articles\n",
    "    \"\"\"\n",
    "    xmldoc = minidom.parse(xmlfile)\n",
    "    idlist = xmldoc.getElementsByTagName('id')\n",
    "    titlelist = xmldoc.getElementsByTagName('title')\n",
    "    textlist = xmldoc.getElementsByTagName('text')\n",
    "    \n",
    "    titles = [title.childNodes[0].data for title in titlelist]\n",
    "    urllist = ['https://en.wikipedia.org/wiki/%s' % (title.replace(' ', '_'))\n",
    "              for title in titles]\n",
    "    typelist = [get_page_type(title) for title in titles]\n",
    "    \n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    word_data = [(id.childNodes[0].data, title, url, page_type,\n",
    "                  tokenizer.tokenize(text.childNodes[0].data.lower()))\n",
    "                for id, title, url, page_type, text in zip(idlist, titles, urllist, typelist, textlist)\n",
    "                if page_type == 'article']\n",
    "    word_data_df = pd.DataFrame(word_data, columns=['id', 'title', 'url', 'type', 'words'])\n",
    "    #word_data_df.to_csv('word_data_df.csv')\n",
    "    return(word_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmlfile = 'Wikipedia-dog.xml'\n",
    "df1 = xml_to_df(xmlfile)\n",
    "#xmlfile = 'Wikipedia-fish.xml'\n",
    "#df2 = xml_to_df(xmlfile)\n",
    "word_data_df = df1 #.append(df2)\n",
    "#word_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dictionary(documents):\n",
    "    \"\"\"\n",
    "    construct a dictionary, i.e. mapping btwn word ids and their freq of occurence in the whole corpus\n",
    "    filter dictionary to remove stopwords and words occuring < min_count times\n",
    "    \n",
    "    input: documents is an iterable consisting of all the words in the corpus \n",
    "    output: filtered dictionary\n",
    "    \"\"\"\n",
    "    dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "    stop_words = nltk.corpus.stopwords.words('english') \n",
    "    min_count = 2\n",
    "    stop_ids = [dictionary.token2id[word] for word in stop_words\n",
    "               if word in dictionary.token2id]\n",
    "    rare_ids = [id for id, freq in dictionary.dfs.items()\n",
    "                if freq < min_count]\n",
    "    dictionary.filter_tokens(stop_ids + rare_ids)\n",
    "    dictionary.compactify()\n",
    "    return(dictionary)\n",
    "\n",
    "def make_corpus(word_data_df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    documents = word_data_df['words'].values\n",
    "    dictionary = make_dictionary(documents)\n",
    "    # convert corpus to vectors using bag-of-words representation, i.e. tuples of word indices and word counts\n",
    "    corpus = [dictionary.doc2bow(words) for words in documents]\n",
    "    return(corpus, dictionary)\n",
    "\n",
    "def make_lsi_similarity_matrix(tfidf_corpus, dictionary):\n",
    "    \"\"\"\n",
    "    construct LSI (latent semantic indexing) model on Tfidf-transformed corpus, print model topics, \n",
    "    return similarity matrix.\n",
    "    \"\"\"\n",
    "    # construct model\n",
    "    lsi = models.lsimodel.LsiModel(tfidf_corpus, id2word=dictionary, num_topics=200) \n",
    "    lsi.save('wiki.lsi')\n",
    "    for i, topic in enumerate(lsi.print_topics(5)[:3]):\n",
    "        print('Topic: ', format(i))\n",
    "        print(str(topic).replace(' + ', '\\n')) \n",
    "        print('') \n",
    "    # create similarity matrix\n",
    "    matsim = similarities.MatrixSimilarity(lsi[tfidf_corpus], num_best=6)\n",
    "    return(matsim)\n",
    "\n",
    "def print_similar_articles(word_data_df, matsim, num_print):\n",
    "    \"\"\"http://localhost:8888/notebooks/CDIPS_Content_Rec/melanie/wikipedia_topic_modeling_to_db.ipynb#\n",
    "    print titles of first num_print articles and their most similar articles and similarity scores.\n",
    "    this is independent of model used.\n",
    "    \"\"\"\n",
    "    titles = word_data_df['title']\n",
    "    # for the first num_print articles, print most similar articles and their similarity scores\n",
    "    for sims in list(matsim)[:num_print]:\n",
    "        title_index = sims[0][0]\n",
    "        print(titles[title_index]) \n",
    "        for other_title_index, score in sims[1:]:\n",
    "            print('\\t', titles[other_title_index], ' ', score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.99999988079071045),\n",
       "  (54, 0.33596238493919373),\n",
       "  (43, 0.27727752923965454),\n",
       "  (6, 0.17250028252601624),\n",
       "  (22, 0.13536316156387329),\n",
       "  (34, 0.12215814739465714)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim=list(lsi_matsim)\n",
    "sim[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-29e259f0495a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-38-29e259f0495a>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    other_titles = [titles[title_ind] for title_ind, score in sims[1:] for sims in list(lsi_matsim)]\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# make dataframe with (1) article title, (2) url, (3) list of similar articles, (4) list of urls for similar articles, \n",
    "# (5) list of similarity scores\n",
    "titles = word_data_df[['title']]\n",
    "urls = word_data_df[['url']\n",
    "other_titles = [titles[title_ind] for title_ind, score in sims[1:] for sims in list(lsi_matsim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic:  0\n",
      "(0, '0.301*\"cat\"\n",
      "0.219*\"cats\"\n",
      "0.192*\"dog\"\n",
      "0.155*\"journal\"\n",
      "0.115*\"meat\"\n",
      "0.094*\"name\"\n",
      "0.091*\"dogs\"\n",
      "0.090*\"feral\"\n",
      "0.090*\"doi\"\n",
      "0.089*\"volume\"')\n",
      "\n",
      "Topic:  1\n",
      "(1, '0.415*\"cat\"\n",
      "0.345*\"cafe\"\n",
      "-0.316*\"dog\"\n",
      "0.250*\"cats\"\n",
      "0.138*\"café\"\n",
      "-0.132*\"dogs\"\n",
      "-0.130*\"breed\"\n",
      "-0.111*\"wagging\"\n",
      "-0.111*\"kennel\"\n",
      "-0.104*\"breeds\"')\n",
      "\n",
      "Topic:  2\n",
      "(2, '0.273*\"meat\"\n",
      "-0.253*\"bites\"\n",
      "0.224*\"cafe\"\n",
      "-0.222*\"bite\"\n",
      "-0.173*\"rabies\"\n",
      "-0.161*\"cdc\"\n",
      "0.144*\"festival\"\n",
      "0.135*\"china\"\n",
      "-0.127*\"infection\"\n",
      "-0.114*\"wagging\"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus, dictionary = make_corpus(word_data_df)\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "lsi_matsim = make_lsi_similarity_matrix(tfidf[corpus], dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kennel\n",
      "\t Cattery   0.335962384939\n",
      "\t Indian National Kennel Club   0.27727752924\n",
      "\t Breed type (dog)   0.172500282526\n",
      "\t Dog World (newspaper)   0.135363161564\n",
      "\t Lists of dogs   0.122158147395\n",
      "Cynology\n",
      "\t Dog   0.143377020955\n",
      "\t Breed type (dog)   0.127784788609\n",
      "\t Cat training   0.124675229192\n",
      "\t Pussy   0.117153279483\n",
      "\t Felinology   0.108356624842\n",
      "Pack (canine)\n",
      "\t Canid hybrid   0.270516097546\n",
      "\t Dog   0.224993467331\n",
      "\t Origin of the domestic dog   0.217068359256\n",
      "\t Canine reproduction   0.162874683738\n",
      "\t Cat   0.104910813272\n",
      "Rare breed (dog)\n",
      "\t Breed type (dog)   0.329889953136\n",
      "\t Lists of dogs   0.166610077024\n",
      "\t Dog   0.16474558413\n",
      "\t Dog bite   0.133017197251\n",
      "\t Origin of the domestic dog   0.1178458184\n",
      "Dogs in ancient China\n",
      "\t Dogs in Mesoamerica   0.203201308846\n",
      "\t Dog   0.200637221336\n",
      "\t Origin of the domestic dog   0.200029179454\n",
      "\t Dog meat   0.185686558485\n",
      "\t Panhu   0.175255656242\n",
      "Dog biscuit\n",
      "\t Dog food   0.25327244401\n",
      "\t Dog meat   0.155288115144\n",
      "\t Dog daycare   0.128972351551\n",
      "\t Cat meat   0.128386080265\n",
      "\t Dog   0.0973159447312\n",
      "Breed type (dog)\n",
      "\t Rare breed (dog)   0.329889953136\n",
      "\t Indian National Kennel Club   0.202926948667\n",
      "\t Dog World (newspaper)   0.198463663459\n",
      "\t Kennel   0.172500282526\n",
      "\t Dog   0.170514181256\n",
      "Canid hybrid\n",
      "\t Origin of the domestic dog   0.401132106781\n",
      "\t Dog   0.362283140421\n",
      "\t Interbreeding of dingoes with other domestic dogs   0.354888349771\n",
      "\t Pack (canine)   0.270516097546\n",
      "\t Cat   0.172829955816\n",
      "Canine physical therapy\n",
      "\t Therapy cat   0.303683400154\n",
      "\t Cynophobia   0.154859542847\n",
      "\t Human–canine bond   0.130635038018\n",
      "\t Cat anatomy   0.10080563277\n",
      "\t Dog   0.0876861959696\n",
      "Dogs in Mesoamerica\n",
      "\t Dogs in ancient China   0.203201308846\n",
      "\t Dog   0.170912578702\n",
      "\t Dogs in religion   0.165916323662\n",
      "\t Dog meat   0.15780878067\n",
      "\t Origin of the domestic dog   0.13782773912\n"
     ]
    }
   ],
   "source": [
    "print_similar_articles(word_data_df, lsi_matsim, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_rp_similarity_matrix(tfidf_corpus, dictionary):\n",
    "    \"\"\"\n",
    "    construct RP (random projections) model on Tfidf-transformed corpus, print model topics, \n",
    "    return similarity matrix.\n",
    "    \"\"\"\n",
    "    # construct model\n",
    "    rp = models.RpModel(corpus=tfidf_corpus, id2word=dictionary, num_topics=200)\n",
    "    rp.save('wiki.rp_model')\n",
    "    # create similarity matrix\n",
    "    matsim = similarities.MatrixSimilarity(rp[tfidf_corpus], num_best=6)\n",
    "    return(matsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kennel\n",
      "\t Cattery   0.473478198051\n",
      "\t Indian National Kennel Club   0.353589355946\n",
      "\t Breed type (dog)   0.336074620485\n",
      "\t Lists of dogs   0.215678781271\n",
      "\t Dog bite   0.212287530303\n",
      "Cynology\n",
      "\t Dog meat   0.217460200191\n",
      "\t Feline zoonosis   0.203232139349\n",
      "\t Therapy cat   0.201697513461\n",
      "\t Pet Check Technology   -0.145228013396\n",
      "\t Rabies in Haiti   0.142572551966\n",
      "Pack (canine)\n",
      "\t Dogs in the American Revolutionary War   -0.173008412123\n",
      "\t Dog   0.172464832664\n",
      "\t Exotic felines as pets   0.167812645435\n",
      "\t PDSA Certificate for Animal Bravery or Devotion   -0.164077565074\n",
      "\t Canid hybrid   0.163395106792\n",
      "Rare breed (dog)\n",
      "\t Breed type (dog)   0.274982780218\n",
      "\t Lists of dogs   0.228078782558\n",
      "\t Dogs in religion   0.171975374222\n",
      "\t Cat bite   0.17196701467\n",
      "\t Cultural depictions of cats   0.156541839242\n",
      "Dogs in ancient China\n",
      "\t Origin of the domestic dog   0.270263642073\n",
      "\t Dog   0.229469776154\n",
      "\t Panhu   0.222705617547\n",
      "\t Canid hybrid   0.198899462819\n",
      "\t Dog meat   0.182176455855\n",
      "Dog biscuit\n",
      "\t Dog food   0.276397109032\n",
      "\t Dog daycare   0.210519641638\n",
      "\t PDSA Certificate for Animal Bravery or Devotion   0.177337706089\n",
      "\t My Life in Dog Years   0.157343283296\n",
      "\t Therapy cat   -0.156944811344\n",
      "Breed type (dog)\n",
      "\t Kennel   0.336074620485\n",
      "\t Rare breed (dog)   0.274982780218\n",
      "\t Dog   0.205246761441\n",
      "\t Dogs in religion   0.191642642021\n",
      "\t Indian National Kennel Club   0.185083091259\n",
      "Canid hybrid\n",
      "\t Origin of the domestic dog   0.401743024588\n",
      "\t Dog   0.319059312344\n",
      "\t Cat   0.277988940477\n",
      "\t Cattery   0.254464447498\n",
      "\t Pussy   0.225741788745\n",
      "Canine physical therapy\n",
      "\t Therapy cat   0.332921981812\n",
      "\t Cabbit   0.225102588534\n",
      "\t Cynophobia   0.194141760468\n",
      "\t Cropping (animal)   0.176425412297\n",
      "\t Cat senses   0.163238629699\n",
      "Dogs in Mesoamerica\n",
      "\t Operation Cat Drop   0.233144402504\n",
      "\t Jed (wolfdog)   0.192279726267\n",
      "\t Pink cat   0.151978969574\n",
      "\t Rare breed (dog)   0.149735227227\n",
      "\t Rabies in Haiti   -0.141977548599\n"
     ]
    }
   ],
   "source": [
    "rp_matsim = make_rp_similarity_matrix(tfidf[corpus], dictionary)\n",
    "print_similar_articles(word_data_df, rp_matsim, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
